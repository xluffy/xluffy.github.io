<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Sidekiq, how to reliability? | xluffy&#39;s page</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
    <header>

  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <nav>
    <ul>
      
      
      <li class="pull-left ">
        <a href="https://xluffy.github.io">/home/xluffy&#39;s page</a>
      </li>
      
      
      <li class="pull-left ">
        <a href="/categories/">~/categories</a>
      </li>
      
      
      <li class="pull-left ">
        <a href="https://github.com/xluffy/til/issues">~/til</a>
      </li>
      
      
      <li class="pull-left ">
        <a href="#">~/books</a>
      </li>
      

      
      
      <li class="pull-right">
        <a href="/index.xml">~/subscribe</a>
      </li>
      

    </ul>
  </nav>
</header>

    
    
      
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
          new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
            'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer','GTM-K4LWNXV');</script>
      
    
  </head>

  <body>
    
      
        <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-K4LWNXV" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
      
    
    <br/>

<div class="article-meta">
<h1><span class="title">Sidekiq, how to reliability?</span></h1>

<h2 class="date">2018/07/26</h2>
<p class="terms">
  
  
  Categories: <a href="/categories/rails">rails</a> 
  
  
  
  
</p>
</div>



<main>


<p>Thông thường, khi xây dựng một ứng dụng web, quy trình đơn giản sẽ như sau:</p>

<ul>
<li>Người dùng gửi yêu cầu, request tới web application.</li>
<li>Web application nhận request, xử lý (hoặc intergration với service khác như database để xử lý).</li>
<li>Cuối cùng trả về kết quả cho user.</li>
</ul>

<p>Ví dụ trong thực tế, bạn đăng ký user ở một website nào đó, sau khi nhập đầy đủ thông tin, submit -&gt; request sẽ được gửi lên server và người dùng sẽ <strong>chờ</strong> cho tới khi server xử lý xong và trả về kết quả (thành công hoặc thất bại). Do người dùng phải <strong>chờ</strong> nên ta gọi đó là synchronous task.</p>

<p>Tuy nhiên trong thực tế, không phải lúc nào web app cũng xử lý nhanh hoặc không phải lúc nào chúng ta cũng cần <strong>phản hồi ngay lập tức</strong> kết quả cho người dùng. Ví dụ sau khi đăng ký ta có gửi email thông báo tới cho người dùng, nhưng không nhất thiết phải gửi email <strong>ngay lập tức</strong> cho người dùng, có thể chậm 1-2 phút cũng chấp nhận được hoặc ví dụ các tác vụ resize, optimize ảnh do người dùng upload thường tốn nhiều thời gian, nếu để user chờ ở màn hình upload cũng không phải là cách hay.</p>

<p>Những tác vụ như vậy ta có thể đưa vào chạy nền hay còn gọi là backgroud job/asynchronous job. Giúp tránh bắt người dùng phải chờ đợi lâu mà vẫn đảm bảo là sẽ xử lý tác vụ đó cho người dùng.</p>

<p>Mô hình chung sẽ như sau:</p>

<p><img src="https://drivy.engineering/assets/posts/2015-10-12-taskqueues-go-wild/taskqueues.svg" alt="task-queue" /></p>

<p><em>image source from <a href="https://drivy.engineering/taskqueues-tips">https://drivy.engineering/taskqueues-tips</a></em></p>

<ul>
<li>Broker là một queue ví dụ như redis, RabbitMQ.</li>
<li>App sẽ enqueue các tác vụ cần xử lý background tùy vào từng request.</li>
<li>CRON sẽ enqueue các bg job định kỳ vào những thời điểm cụ thể.</li>
<li>Worker sẽ dequeue và xử lý các tác vụ đó.</li>
</ul>

<p>Sidekiq là một background processing framework cho ngôn ngữ Ruby để giải quyết các bài toán tương tự như trên. Xử lý background không phải là bài toán mới, bất kỳ ngôn ngữ lập trình nào cũng có những cách giải quyết tương tự, về job queue cũng có rất nhiều lựa chọn khác nhau ví dụ <a href="http://gearman.org">Gearmand</a>, <a href="http://www.celeryproject.org">Celery</a>, <a href="http://python-rq.org">rq</a>.</p>

<p>Các xử lý mà sẽ phù hợp để đưa vào chạy nền bao gồm:</p>

<ul>
<li>Các xử lý nặng về CPU, ví dụ các phép tính toán học hoặc phân tích cấu trúc.</li>
<li>Các xử lý nặng về I/O ví dụ load data tính toán report, ETL.</li>
<li>Batch job ví dụ như update/processing report về đêm.</li>
<li>&hellip;</li>
</ul>

<h2 id="1-sidekiq-architecture">1. Sidekiq Architecture</h2>

<p>Sidekiq gồm 3 phần chính:</p>

<ul>
<li>Sidekiq client chạy trên bất kỳ Ruby process nào đó ví dụ như <code>puma</code> hoặc <code>passsenger</code> cho phép <strong>tạo</strong> job để xử lý sau.</li>
<li>Redis là data storage cho sidekiq, dùng để lưu trữ các job được đẩy xuống từ sidekiq client.</li>
<li>Sidekiq server là một process độc lập, <strong>pull job</strong> từ queue trong Redis và xử lý.</li>
</ul>

<p><img src="https://brandonhilkert.com/images/sidekiq/rails-web-worker.png" alt="sidekiq-flow" />
<em>image source from <a href="https://brandonhilkert.com/blog/sidekiq-as-a-microservice-message-queue">https://brandonhilkert.com/blog/sidekiq-as-a-microservice-message-queue</a></em></p>

<p>Đứng ở góc độ vận hành hệ thống, mình chỉ quan tâm chuyện gì xảy ra khi bất cứ thành phần trên fail và làm cách nào để đảm bảo hệ thống có khả năng fail-over. Để trả lời câu hỏi đó thì cần phải hiểu cách hoạt động, implement của sidekiq.</p>

<h2 id="2-how-to-reliability">2. How to Reliability?</h2>

<h3 id="2-1-sidekiq-client">2.1 Sidekiq client</h3>

<p>Khi sidekiq client push một job tới redis, giả định rằng network không hoạt động tốt, dẫn tới job không thể lưu trữ vào redis, vậy làm sao đảm bảo độ tin cậy cho sidekiq client? Một hướng tiếp cận đó là implement một local queue để lưu trữ các job nếu gọi network fail và sẽ delivery khi network kết nối thành công. <code>fluentd</code> cũng có một cách tương tự gọi là buffer, logstash cũng có cách giải quyết tương tự là <em>persistent queue</em>. Tuy nhiên nó cũng có một số nhược điểm:</p>

<ul>
<li>local queue per-process và in-memory, nếu client process bị restart thì job vẫn bị mất.</li>
<li>sidekiq chỉ lưu 1000 job cuối cùng để tránh lưu quá nhiều dẫn tới full mem.</li>
</ul>

<h3 id="2-2-redis">2.2 Redis</h3>

<p>Redis được dùng để lưu trữ các job cần xử lý, nếu storage fail ta mất tất cả các job chưa kịp xử lý và người dùng sẽ không nhận được thứ mà họ cần.</p>

<p>Câu hỏi là tại sao lại là redis chứ không phải cái gì khác? Và làm sao đảm bảo dù fail cũng phải đảm bảo tác vụ của người dùng được xử lý.</p>

<ul>
<li>Redis có tốc độ read/write operation rất tốt so với các storage khác như MySQL nên dùng redis lợi hơn về mặt tốc độ (Gearman có hỗ trợ persistent vào MySQL và memcached)</li>
<li>Nếu so với memcached thì redis hỗ trợ nhiều kiểu dữ liệu hơn và vẫn có cơ chế persistent dữ liệu xuống đĩa cứng định kỳ, tất nhiên nếu redis fail mà chưa kịp persistent dữ liệu xuống thì vẫn mất job tuy nhiên vùng dữ liệu bị mất sẽ nhỏ hơn.</li>
<li>Tuy nhiên nếu redis server chết hẳn thì sidekiq client sẽ không thể đẩy job vào redis được, có nghĩa là người dùng vẫn bị stuck. Lúc này ta có thể sử dụng redis sentinel (master-slave) vừa đảm bảo việc persistent job vừa đảm bảo failover nếu 1 server chết.</li>
<li>Redis chạy ổn khi tất cả data fit vừa với memory, nếu full mem redis sẽ evict data theo policy mà ta cấu hình, ví dụ LRU -&gt; mất các job cũ chưa kịp xử lý nên để đảm bảo không evict nhầm nên cấu hình redis <code>maxmemory-policy noeviction</code>.</li>
<li>Redis thường được xài để cache dữ liệu, tuy nhiên bản chất của việc cache và storage job là khác nhau (cache có thể invalidate nhưng job thì không được mất), nên tốt nhất là xài tách rời 2 server redis cho việc cache và lưu job sidekiq.</li>
<li>Một lý do nữa nên tách redis dùng cho cache và redis dùng để storage backgroud job cho sidekiq là timeout. Khi full mem, để không bị OOM redis sẽ xài tới swap -&gt; disk swapping -&gt; tăng độ trễ khi đọc dữ liệu. Hoặc nếu có các command latency trên redis mà tốn thời gian cũng gây ra độ trễ khi pull job.</li>
</ul>

<h3 id="2-3-sidekiq-server">2.3 Sidekiq server</h3>

<p>Câu hỏi đặt ra là:</p>

<ul>
<li>Nếu sidekiq xử lý liên tục thì làm sao để restart sidekiq khi một job đang được sidekiq xử lý?</li>
<li>Nếu job bị lỗi, exception thì cơ chế nào để retry?</li>
<li>Nếu sidekiq server đang xử lý một job, nhưng bị segfault hoặc crash hoặc force kill (kill -9) thì làm sao đảm bảo job vẫn sẽ được xử lý.</li>
</ul>

<p>Về câu hỏi đầu tiên, đây là một điểm khá thú ví về cách thiết kế, nếu ai quen với nginx sẽ thấy một cơ chế tương tự. Phần giải thích này thực chất là phần <a href="https://github.com/mperham/sidekiq/wiki/Signals">Signals</a> trong wiki của Sidekiq.</p>

<ul>
<li>Khi ta gửi TSTP signal tới sidekiq (<code>kill -TSTP [sidekiq_pid]</code>), Sidekiq sẽ hiểu là nó sẽ bị shutdown trong tương lai gần, sidekiq sẽ chuyển sang trạng thái &ldquo;quiet&rdquo; nghĩa là nó sẽ dừng việc fetch new job từ redis nhưng vẫn tiếp tục xử lý các job mà nó đang giữ, khi tất cả các current job được xử lý xong thì sidekiq sẽ shutdown.</li>
<li>TERM signal nghĩa là Sidekiq nên shutdown sau khoảng thời thời gian <code>-t</code> timeout. Tương tự như <code>TSTP</code> sidekiq cũng sẽ không fetch job mới nhưng vẫn tiếp tục xử lý các job cũ cho xong. Điểm khác biệt là sau timeout nếu job không được <strong>hoàn thành</strong> thì sẽ bị force terminated và message đó sẽ được <strong>push back</strong> lại vào redis, để lần sau khi sidekiq được start job đó sẽ được fetch lại và được xử lý.</li>
</ul>

<p>=&gt; Best practice là ta sẽ gửi signal <code>TSTP</code> lúc bắt đầu deploy và <code>TERM</code> lúc kết thúc deploy. Và lúc này có thể thoải mái restart mà không sợ bị miss bất cứ job nào.</p>

<p>Sidekiq có built-in một chơ chế để retry, sẽ catch các exception và tự động retry thường xuyên dựa trên công thức <code>(retry_count ** 4) + 15 + (rand(30) * (retry_count + 1))</code> (tương đương 15, 16, 31, 96, 271, &hellip; giây + một lượng random time), với giá trị <a href="https://github.com/mperham/sidekiq/blob/master/lib/sidekiq/job_retry.rb#L63">default retry là 25</a> nghĩa là để thực hiện 25 lần retry sẽ vào khoảng 21 ngày, trong 21 ngày này ta có thể fix bug, deploy và job sẽ được xử lý thành công ở lần retry tiếp theo.</p>

<p>Nếu sau 25 lần retry và job vẫn không thành công thì sidekiq sẽ chuyển job đó và Dead Job queue và phải can thiệp thủ công để chạy lại job đó. Và nếu sau 6 tháng, job đó không được xử lý thì sidekiq sẽ discard job đó.</p>

<p>Về câu hỏi cuối, làm thế nào để đảm bảo tính tin cậy cho một job khi được fetch bởi sidekiq server, và sidekiq server bị crash thì job đó vẫn có thể được xử lý. Đây là một bài toán rất thú vị để tìm hiểu và qua đó ta sẽ thấy sức mạnh của redis.</p>

<p>Trước tiên ta sẽ nói 1 chút xíu về list và queue trong redis. Trong redis thì list là một tập hợp của các phần tử có kiểu dữ liệu là string đã được sắp xếp bằng thuật toán insertion sort. List trong redis được implement bằng cấu trúc dữ liệu là <a href="https://redis.io/topics/data-types-intro">linked list</a>.</p>

<p>Redis hỗ trợ một số lệnh trên list như <code>LPUSH, RPUSH, LPOP, RPOP, LLEN, LINSERT, LINDEX</code>, với tập lệnh này ta có thể dùng list trong redis như queue (FIFO với tập lệnh LPUSH, RPOP, phần tử thêm vào đầu tiên sẽ được lấy ra đầu tiên) hoặc stack (LIFO với tập lệnh RPUSH, LPOP, phần tử thêm vào đầu tiên sẽ được lấy ra sau cùng).</p>

<p>Bằng cách sử dụng list như queue ta có thể implement producer để đẩy dữ liệu và consumer để lấy dữ liệu từ trong queue ra với 2 step đơn giản:</p>

<ul>
<li>push item vào list, producer gọi LPUSH.</li>
<li>lấy item trong list, đem ra xử lý, consumer gọi RPOP.</li>
</ul>

<p>Vấn đề là không phải lúc nào list của chúng ta cũng có phần tử, và khi list không có phần tử thì sẽ consumer sẽ không có gì để xử lý cả, lệnh RPOP trả về <code>nil</code>.</p>

<pre><code>127.0.0.1:6379&gt; LPUSH sidekiq a b c
(integer) 3
127.0.0.1:6379&gt; LLEN sidekiq
(integer) 3
127.0.0.1:6379&gt; RPOP sidekiq
&quot;a&quot;
127.0.0.1:6379&gt; RPOP sidekiq
&quot;b&quot;
127.0.0.1:6379&gt; RPOP sidekiq
&quot;c&quot;
127.0.0.1:6379&gt; RPOP sidekiq
(nil)
</code></pre>

<p>Để giải quyết vấn đề trên, ta có thể bắt consumer đợi trong một khoảng thời gian nào đó và sau đó sẽ gọi lại LPOP để lấy dữ liệu, kỹ thuật này gọi là <em>polling</em>. Tuy nhiên kỹ thuật này vẫn có nhược điểm:</p>

<ul>
<li>Nếu lần gọi lại RPOP để lấy dữ liệu mà list vẫn rỗng nghĩa là consumer tốn công xử lý một lệnh vô nghĩa và redis server cũng tốn công xử lý mà không đạt được kết quả gì.</li>
<li>Tăng thời gian để gọi lại RPOP lấy dữ liệu, nghĩa là sau khi consumer nhận về <code>nil</code> thì sẽ đợi một khoảng thời gian rồi mới RPOP lại. Tuy nhiên delay-time mà cao thì có thể sẽ có một lượng lớn item được push vào list rồi mà delay-time mà quá ngắn thì lại quay về vấn đề số 1, gọi lệnh vô nghĩa.</li>
</ul>

<p>Do đó redis implement một số lệnh gọi là blocking operation đó là BLPOP và BRPOP. Nghĩa là nếu list rỗng, thay vì trả về <code>nil</code> thì consumer sẽ block connection và chờ với một khoảng thời gian timeout (ta có thể chờ vô tận bằng cách set timeout = 0), khi có một item mới được thêm vào list thì POP ra và xử lý. Điểm khác biệt là không cần phải định kỳ quay trở lại kiểm tra -&gt; tránh thực hiện các lệnh vô nghĩa.</p>

<p>Quay trở lại vấn đề của sidekiq server, sidekiq dùng lệnh <code>BRPOP</code> để fetch một job từ trong queue redis ra và xử lý, không có gì phải bàn cãi về việc tại sao lại dùng <code>BRPOP</code> nữa, tuy nhiên việc dùng <code>BRPOP</code> hay <code>RPOP</code> bị một vấn đề là sau khi sidekiq fetch job thì <strong>job đó không còn tồn tại trong redis</strong>. Và bây giờ, nếu sidekiq crash, job vừa được fetch ra, chưa kịp xử lý sẽ biến mất hoàn toàn.</p>

<p>Tóm lại, đen thôi, đỏ quên đi, nếu quay trở lại vấn đề restart, sidekiq có shutdown thì vẫn có thể <code>push-back</code> job lại về redis chứ đã crash giữa đường job sẽ không có cách nào cứu chữa.</p>

<p>Vậy thử nghĩ xem có cách nào để đảm bảo tính tin cậy khi xử lý job, theo cách suy nghĩ thông thường thì ĐƠN GIẢN là khi fetch job thì đừng XÓA job đó ra khỏi queue của redis. Tuy nhiên nó dẫn tới một vấn đề khác đó là một sidekiq server khác có thể <strong>nhìn thấy</strong> job đó, fetch ra và xử lý job đó. Hệ quả là job được xử lý 2 lần, nếu bạn gửi mail thì có nghĩa là người dùng sẽ nhận được 2 email có cùng nội dung.</p>

<p>Một cách tiếp cận khác là thay vì giữ job đó trong queue thì ta vẫn cứ fetch job đó ra nhưng sau đó sẽ push job đó vào một queue khác gọi là <code>queue_đang_xử_lý</code>. Đây chính xác là cách lệnh <code>RPOPLPUSH</code> trong redis hoạt động, <a href="https://redis.io/commands/rpoplpush">reliable queue pattern</a>. Lệnh này:</p>

<ul>
<li>Fetch và xóa last-item (tail) từ queue cũ và cùng thời điểm đó thêm item đó đầu một queue khác -&gt; gọi là <em>processing_queue</em> (head).</li>
<li>Atomically return nghĩa là hoạt động như transaction trong database, 1 là thành công thì commit (xóa từ queue cũ và thêm vào queue mới), 2 là fail thì rollback, trả job về lại queue cũ.</li>

<li><p>Dùng lệnh <code>LREM</code> theo thứ tự để xóa item trong <em>processing_queue</em> một khi item đó đã được xử lý xong</p>

<pre><code>127.0.0.1:6379&gt; LPUSH sidekiq a b c
(integer) 3
127.0.0.1:6379&gt; RPOPLPUSH sidekiq sidekiq_current_processing
&quot;a&quot;
127.0.0.1:6379&gt; LRANGE sidekiq 0 -1
1) &quot;c&quot;
2) &quot;b&quot;
127.0.0.1:6379&gt; LRANGE sidekiq_current_processing 0 -1
1) &quot;a&quot;
</code></pre></li>
</ul>

<p>Với Sidekiq Pro, để đảm bảo tính tin cậy thì thay vì dùng <code>fetch</code> ta có hàm <code>super_fetch</code> sử dụng <code>RPOPLPUSH</code> như cách ở trên.</p>

<h3 id="2-4-others">2.4 Others</h3>

<p>Mặc định, sidekiq sử dụng duy nhất một queue là <code>default</code> trong redis. Nếu muốn sử dụng nhiều queue thì chỉ việc định nghĩa thêm queue, và vấn đề tiếp theo là làm thế nào để biết queue nào được ưu tiên xử lý.</p>

<p>Ví dụ ta có 2 queue sau:</p>

<pre><code>sidekiq -q critical,2 -q default
</code></pre>

<p>Chỉ số phía sau queue gọi là weight của queue, queue <code>critical</code> sẽ được check/fetch 2 lần so với queue default có weight là 1.</p>

<p>Hoặc nếu muốn xử lý job theo thứ tự khai báo, đơn giản là định nghĩa queue không có trọng số</p>

<pre><code>sidekiq -q critical -q default -q low
</code></pre>

<p>=&gt; Nghĩa là job trong <code>default</code> queue chỉ được xử lý khi <code>critical</code> queue rỗng.</p>

<p>Một số vấn đề khác về bao nhiêu queue là đủ, concurrent của sidekiq bao nhiêu là hợp lý có thể tìm thấy trong <a href="https://github.com/mperham/sidekiq/wiki/Advanced-Options#concurrency">wiki sidekiq</a></p>

<h2 id="3-chốt">3. Chốt</h2>

<p>Nhưng tui đâu có biết Ruby đâu, vậy tại sao tui phải đọc bài này làm chi? Thực ra mục đích ban đầu của mình là tìm hiểu một số vấn đề của sidekiq như bao nhiêu queue là đủ, bao nhiêu sidekiq process hoặc tại sao lại timeout nhưng sau khi tìm hiểu xong học thêm đc khá nhiều thứ hay ho về cách thiết kế, implement và một số khái niệm mới:</p>

<ul>
<li>list/queue/blockingqueue và cách redis implement</li>
<li>Reliable queue</li>
<li>polling và long-polling</li>
</ul>

<p>Ngoài ra, sau khi đọc bài này bạn cũng sẽ hiểu một số metric cần thiết cho việc monitor nhằm đảm bảo tính tin cậy cho xử lý backgroud job, ví dụ một số metric cần lưu ý như:</p>

<ul>
<li>Ở phía client phải alert trong trường hợp network fail không thể connect tới queue.</li>
<li>Ở redis queue phải đảm bảo rằng redis luôn availability, ngoài ra cần monitor thêm về số lượng job in queue, nếu số lượng job trong queue vượt ngưỡng nào đó có nghĩa là worker đang bị stuck hoặc số worker không đủ để xử lý đủ lượng job enqueue hoặc tất cả worker đều đang chết.</li>
<li>Ở Worker cần phải monitor worker sống hay chết, và phải monitor thêm về thời gian xử lý các job, từ đây sẽ biết cách để tăng số worker hay tối ưu lại xử lý.</li>
</ul>

<h2 id="4-ref">4. Ref</h2>

<ul>
<li><a href="https://github.com/mperham/sidekiq/wiki">https://github.com/mperham/sidekiq/wiki</a></li>
<li><a href="https://redis.io/topics/data-types-intro">https://redis.io/topics/data-types-intro</a></li>
<li><a href="https://redis.io/commands/blpop">https://redis.io/commands/blpop</a></li>
<li><a href="https://redis.io/commands/rpoplpush">https://redis.io/commands/rpoplpush</a></li>
<li><a href="https://docs.microsoft.com/en-us/azure/architecture/best-practices/background-jobs">https://docs.microsoft.com/en-us/azure/architecture/best-practices/background-jobs</a></li>
</ul>

</main>

    <footer>
      
<script>
(function() {
  function center_el(tagName) {
    var tags = document.getElementsByTagName(tagName), i, tag;
    for (i = 0; i < tags.length; i++) {
      tag = tags[i];
      var parent = tag.parentElement;
      
      if (parent.childNodes.length === 1) {
        
        if (parent.nodeName === 'A') {
          parent = parent.parentElement;
          if (parent.childNodes.length != 1) continue;
        }
        if (parent.nodeName === 'P') parent.style.textAlign = 'center';
      }
    }
  }
  var tagNames = ['img', 'embed', 'object'];
  for (var i = 0; i < tagNames.length; i++) {
    center_el(tagNames[i]);
  }
})();
</script>

      
      <hr/>
      <a href="https://github.com/xluffy">Github</a> | <a href="https://twitter.com/min0lta">Twitter</a> | <a href="https://t.me/xluffy">Telegram</a>
      
      <br><a href="https://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png"></a>
    </footer>
  </body>
</html>

